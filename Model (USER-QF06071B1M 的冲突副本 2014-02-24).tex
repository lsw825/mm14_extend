\section{OUR APPROACH}
\subsection{Preliminaries}
In social media, we can extract not only visual features but also a series of social contextual information of an image, which is called social factors in our problem. The social factors are usually complex and unstructured. Therefore, it is important to present an image in a unified and structured form. Using the idea of the Bag-of-Words (BOW) model in traditional features, we can design a ``Bag-of-Visual-Entities" model to represent a social factor. For example, for an image in Flickr, the bag of users who favored this image can be regarded as a social factor. Thus, a social image can be represented in visual features and social factors two dimensions, i.e., $\mathcal{I}_i = \{\mathnormal{x}_i, \mathcal{S}_i\}$, where $\mathnormal{x}_i$ is the vector of visual features ,$\mathcal{S}_i=\cup_{k=1}^n \mathcal{V}_i^k$ is a set that including $n$ social factors. $\mathcal{V}_i^k$ is the $k^th$ social factor of image $\mathcal{I}_i$. Each social factor $\mathcal{V}_i^k$ denotes a bag of social entities. Except the previous social factor of favored users, in the social image platforms such as Flickr, the typical social factors we can obtained also including the interest groups that the image belongs to, and the tags that are labeled by users, etc. In this section, we use the above three social factors as an example to show our approach intuitively. To make our formulation more general, we use the symbol $V_i$ to represent a social factor, which can be either a set of users, groups or tags. $v_i$ denotes a social entity, which can be either a user, a group or a tag.


For social images, a lot of previous works focus on defining a new metric function $f(\mathcal{I}_i, \mathcal{I}_j )$ based on both visual features and social factors to better measure the distance between pair-wised images. However, for a large scale of Web images, they do not have social attributes. Thus, the methods based on social images cannot be generalized. In this work, our target is to use the idea of metric learning to map visual features to a new space. In this space, the image distances measured by visual features and social attributes are  consistent. Based on this method, we can measure the distance of general Web images by their visual features by the trained function. In another word, our aim is: learning a distance function $f(\mathnormal{x}_i, \mathnormal{x}_j)$, to reduce the distance $f(x_i, x_j)$ for all socially similar images $\mathcal{I}_i$ and $\mathcal{I}_j$.

\subsection{Social Similarity of the Images}
\subsubsection{Specificity of Social Entities}
In social media platforms, the social factors are all generated by users, which is usually noisy and unreliable. Thus the similarity of social factors cannot accurately reflect the similarity of the images. Taking users as an example, some users focus on only one or two categories of images. Therefore, the images favored by them will have high probability to be similar. Oppositely, some people may have a lot of interest points. For the images that have common favored users in this type, the images may have no similarity at all. The same phenomenon occurs in the case of groups and tags. Images in the group named ``lovely dogs" should be similar but the images in the groups named ``beautiful world" may be very diverse. The tag ``Mona Lisa" is specific because its concept is clear but the tag ``NikonD800" is general because it may occur in all the photos taken by this camera. Therefore, it is very important to judge how specific a social entity is. The entity with high specificity should have high weight in evaluating the social similarity of the images.

If an image is favored by two users, we can assume that the interests of these two users are partially similar. Based on this assumption, we can build the similarity graphs of user interests. The nodes are users. The weight of an edge denotes the similarity of the users. We use $Im(v_i)$ to denote the images that $v_i$ favors, i.e.,
 \begin{equation}
 Im(v_i) = \{I_t|v_i \in V_t\}.
 \end{equation}
 In this equation, $V_t$ denotes the all users who favor image $I_t$. Thus if $v_i$ belongs to $V_t$, $Im(v_i)$ is one of the images that $v_i$ favors. Then the similarity can be defined as the Jaccard distance of images that they favor:
 \begin{equation}
 sim(v_i, v_j) = \frac{Im(v_i) \cap Im(v_j)}{Im(v_i)\cup Im(v_j)}.
 \label{sim1}
 \end{equation}
 Based on this similarity graph, we can utilize clustering method to divide users into $k$ clusters. For a given user $v_i$, if all of his neighbors who have common favors with him belong to the same cluster with him, the interest of $u_i$ should be very concentrated. The images belongs to user $v_i$ should have high probability to be similar. Thus, the specificity score of $v_i$  is defined as follows,
\begin{equation}
sp(v_i) = \frac{1}{|c(v_i)\cup_{v_j \in N(v_i)} c(v_j)|},
\label{sp}
\end{equation}
where $k$ is the number of clusters; $N(v_i)$ is the set of neighbor nodes of $v_i$; $c(v_i)$ is the label of $v_i$'s cluster. If all of $v_i$'s neighbors  belong to the same cluster with him, the specificity score $sp(v_i)$ is defined as $1$. On the contrary, if his neighbors cover all of $k$ clusters, $sp(v_i)$ is defined as $1/k$.

This method is also suitable for the cases of using group or tag as social entity. For any entity $v_i$, the pair-wise similarity can be similarly calculated by Equation \ref{sim1} and specificity score can be calculated by Equation \ref{sp}.
\subsubsection{Evaluation of Social Similarity}
After the specificity scores of social entities are calculated, we explore to evaluate the social similarity of pair-wise images based on the scores. For two images $I_i$ and $I_j$, we analyze their similarity in their social factors $V_i$ and $V_j$. If $V_i\cap V_j$ is empty, i.e.,they share no common entities, we define the social similarity as 0. Otherwise, the social similarity is determined by the overlap of the entities and their specificity. Taking users as an example, intuitively, when the users have the same specificity, the images that are favored by similar users should have high similarity. If the images are both favored by a fixed number of users, the images that are favored by more specific users should have higher similarity. Based on the above two considerations, the social similarity of image in the social factor $V_i$ and $V_j$ are defined as follows,
\begin{equation}
sim(V_i, V_j) \!=\! \left\{\!\! \begin{array}{ll}
0, \!\!\!& V_i \cap V_j = \phi\\
\frac{\sum_{v_t\in V_i \cap V_j}sp(v_t)}{\sum_{v_t \in V_i \cup V_j} sp(v_t)}, \!\!\!& \textrm{otherwise}
\end{array}\right.
\label{sim2}
\end{equation}
In Equation \ref{sim2}, the similarity is defined as the weighted Jaccard similarity of $V_i$ and $V_j$. Obviously, this definition of similarity satisfies the previous heuristics. For a social image has multiple social factors, the final similarity of images $I_i$ and $I_j$ is defined as the average of all the social factors' similarity:
\begin{equation}
sim(I_i, I_j) = \frac{1}{n} \sum_{k=1}^n sim(V^k_i, V^k_j).
\label{social_sim}
\end{equation}
In this equation, we use average because different social factors reflect different aspects of image similarity. The final social similarity values from 0 to 1. When the similarity is close to 1, the images are judged as very similar in social dimension. In the other hand, when the similarity is near to 0, we are not very certain that the image are very dissimilar because similar images may also have no social relation. This problem can be solved by multiple sampling. Because of the diversity of the images, for a given image, if we randomly select many socially similar images, the vase majority of them will be truly dissimilar to it.


\subsection{Social-Sensed Image Distance Learning}

\subsubsection{Mahanalobis Distance Function}
%通过欧氏距离引出马氏距离 介绍基本知识
In traditional metric learning researches, Mahalanobis Distance is a widely used metric function because it is very efficient in optimization and calculation, as well as effective enough in most problems. Although some kernel functions are proposed to improve the performance. We do not consider them because the metric function is not the main contribution of this work and may make our method not scalable. Therefore, we use Mahalanobis Distance to evaluate the image distance, which is defined as follows,
\begin{equation}
d_M(\mathnormal{x}_i, \mathnormal{x}_j) = \sqrt{(\mathnormal{x}_i - \mathnormal{x}_j)^TM(\mathnormal{x}_i - \mathnormal{x}_j)},
\label{distance}
\end{equation}
where $M$ is the Mahalanobis matrix, which needs to be learned in our problem; $\mathnormal{x}_i$ is the vector visual feature of image $\mathcal{I}_i$. To guarantee $d$ to be a distance function, $M$ must be positive semidefinite, which is noted as $M $. For $\mathcal{M}\in R^{n \times n}$, there exists $\mathcal{L}\in R^{n \times n}$, which makes $M=L^TL$. Thus, Equation \ref{distance} can be written as:
\begin{equation}
d_M(\mathnormal{x}_i, \mathnormal{x}_j) = \sqrt{(\mathnormal{y}_i - \mathnormal{y}_j)^T(\mathnormal{y}_i - \mathnormal{y}_j)},
\label{distance2}
\end{equation}
where $\mathnormal{y}_i = L\cdot \mathnormal{x}_i$. From Equation \ref{distance2}, we can easily observe that Mahalanobis distance actually linearly maps original visual space to a new space.

\subsubsection{Distance Learning with Social Constraints}
In our metric learning approach, our goal is to learn the Mahanalobis matrix $M$ from the social images, which makes the image distance $d_M(\mathnormal{x}_i, \mathnormal{x}_j)$ consistent to social similarity. i.e., the distance between socially similar images is close and the distance between socially dissimilar images is far.

In metric learning, ``triple" is a widely used concept for optimization. In our approach, a ``triple" $<i, j, k>$ is defined as three images $I_i, I_j$ and $I_k$, where $I_i$ and $I_j$ are socially similar and $I_i$ and $I_k$ are socially dissimilar. Thus, we can train our metric function by reducing $d_M(\mathnormal{x}_i, \mathnormal{x}_j)$ and enlarging $d_M(\mathnormal{x}_i, \mathnormal{x}_k)$. In our method, the training set of triples $\mathcal{T}$ based on social similarities is defined as:
\begin{equation}
\mathcal{T} = \{<i, j, k>|sim(I_i, I_j) >\delta, sim(I_i, I_k) < \epsilon \},
\label{triple}
\end{equation}
where $\delta$ and $\epsilon$ are the thresholds to specify socially similar images and socially dissimilar images. In social media, there are a lot of socially dissimilar images and a few socially similar images. For a given $<x_i, x_j>$, there are a lot of $x_k$ that satisfies the equation \ref{triple}. In our approach we just randomly select $r$ images to avoid explosion of scale and reduce the redundancy. After the set of of triples $\mathcal{T}$ is selected, we need to find the optimal Mahanalobis matrix $M$ that fulfills the following constraints:
\begin{equation}
d^2_M (x_i, x_k) - d^2_M (x_i, x_j) > 1, \exists<i,j,k> \in \mathcal{T}
\label{cons1}
\end{equation}
Following the traditional margin-based matric learning methods\cite{lmnn, nips03}, the margin between two distances is defined as there square error because it is very easy to optimize and have a good performance. In Equation \ref{cons1}, the matrix $M$ that fulfills all the constraints is typically not unique. In this case, we aim to select the $M$ that close to the original unweighted Euclidean Distance, which represents the original visual similarity in our problem. This leads to the following optimization problem:
\begin{flalign}
&\min_M ||M-I||^2_F\\
s.t. & d^2_M (x_i, x_k) - d^2_M (x_i, x_j) > 1, \exists<i,j,k> \in \mathcal{T} \\
& M \
\end{flalign}

In this problem, if there is no constraints, the initial $M$ is $I$, the unit matrix. Thus the distance is original Euclidean distance. After the constraints are added, $M$ is adjusted to fulfill the constraints. However, not all the constraints can be satisfied because some of them may be conflicting. Therefore, we add the slack variables to account for these constraints.  Then our optimization problem can be written as:
\begin{flalign}
&\min_M ||M-I||^2_F + C\sum_{i,j,k} sim(I_i, I_j)\epsilon_{ijk}\\
s.t. & d^2_M (x_i, x_k) - d^2_M (x_i, x_j) > 1 - \epsilon_{ijk}, \exists<i,j,k> \in \mathcal{T}
\end{flalign}


\subsection{Algorithm and Complexity}
Finally, Algorithm \ref{alg} summarizes the details of the proposed Social-sensed Image Distance Learning algorithm. There are three main steps in our algorithm: social similarity computation step, triple selection step, and optimization step. In social similarity computation step, the social similarity of each pair of images is computed by Equation \ref{social_sim}. The time complexity is $\mathcal{O}(n\sum_{i=1}^m f^i)$, where $n$ is the total number of the training images, $m$ is the number of social factors and $f^i$ is the size of the $i^{th}$ social factor. Usually, we have only several social factors, and the size of social factors, such as users, groups and tags have the same or less order of magnitudes with $n$. In the triple selection step, the time complexity is $\mathcal{O}(r\cdot \sum_{i=1}^n |S_i|)$, where $|S_i|$ is the number of the images that socially similar to the $i^{th}$ image and $r$ is a constant that denotes the number of socially dissimilar images sampled. Usually, we have $|S_i| << n$, thus the complexity of this step usually much less than $\mathcal{O}(n^2 r)$. In the last optimization step, the complexity of SDP is $\mathcal{O}(c|T|)$, where $c$ is a constant that are determined by the number of iteration and the length of visual features, as well as $|T|$ denotes the number of selected triples. At the same time, we have $|T| \leq n^2 r$. Finally, the total complexity is $\mathcal{O}(n\sum_{i=1}^m f^i + r\cdot \sum_{i=1}^n |S_i| + c|T|)$. Based on the above analysis, the complexity is no more than $\mathcal{O}(crn^2)$. In another word, the time complexity of our algorithm is square with respect to the number of training images.
