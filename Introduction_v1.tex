\section{INTRODUCTION}
With the fast development of internet, image plays an important role in delivering information. Searching interesting pictures in search engines, viewing and sharing photos in social network become necessary activities in our daily life. Therefore, there is an increasing demand of better understanding images in image processing area, especially for image search and recommendation.

In these two typical types of applications, measuring the distance (or similarity) of pair-wise images is a fundamental and important issue. If a effective metric is obtained, we can easily use existing technologies to achieve good results in image search and recommendation. For example, in image recommendation, we can employ content-based filtering method to find the images that are closest to the historical viewing logs of the user\cite{cbf}; in image search, PageRank model can be applied to rerank the images that are filtered by text-based search engines\cite{visualrank}. However, to date, existing image distance metrics do not perform well to achieve this goal, due to they are not mature to bridge the ``semantic gap" and ``intention gap". In image distance measuring, although two images are similar in high-level semantic concepts, the distance of their visual features may be far away. This is caused by ``semantic gap". In addition, two images in the same concept may also belong to different user demand/interest. Therefore, the users interested in one image are usually not interested in the other, which is called ``intention gap". Although some researches utilized the tag or category information of the images to learn new image distance functions to bridge the ``semantic gap", the ''intention gap", another influential factor in image search and recommendation is usually ignored. Figure \ref{fig1} is an example of this phenomena. In the figure, the visual concept of (a), (b) and (c) are all ``dog". However, in sentiment level, (a) and (b) give us a feeling of ``lovely" but (c) makes us feel ``lonely". When a user is interested in (a), he/she will be more likely to be interested in (b) rather than (c). The traditional image distance metrics fail to capture user intention because they do not have the knowledge about human cognition. As the previous example, to evaluate whether a dog is lovely, the eyes, nose are more important than furs and backgrounds. Therefore, how to evaluate the image distance in user intention level becomes a key problem in improving the user experience of image search and recommendation.

In the past years, image distance in user intention is very difficult to evaluate due to the lack of personal data. With the development of social network, a huge amount of users share their beautiful pictures and view others' in the social media platforms, such as Flickr and Twitter. In these platform, we can obtain not only vast amounts of images but also a series of user behavior information, such as favorite images and interest groups of users.  Researches in social media\cite{social_visual} have shown that social user behavior does help to understand user interest and then estimate user intention. For example, in Figure \ref{fig1}, (a) and (b) have 13 common favored users and belong to 3 common interest groups in Flickr. On the other hand, (a) and (c) have no common favored users and groups. Therefore, social user behavior is a strong tool to help us bridge the intention gap in image distance learning.

However, using user behavior to learn image distance faces the following challenges:

(1) The lack of social information in Web image. Although user behavior in social media platforms does help to understand user intention, most of the Web images do not have user behavior information due to they are not produced by social media platforms. If we design our method only for those images in social media, our method will be extremely circumscribed. Therefore, how to transfer the knowledge of user social behavior to low-level visual features in Web images is a great challenge in our problem.

(2) The diversity of user interests. In social network, users usually have more than one interest points. Although two images have common favored users or belong to the same groups, they may be still dissimilar in user intention. Thus, we also need to take the diversity of user interests into consideration.

(3) The sparsity of user behavior. In traditional image distance learning task, the knowledge of similarity graph is very dense: in most cases, the similarity of any two images is given. However, in social network, most of pair-wise images are not social related. i.e., they do not have any relation in user behavior. Thus, we cannot determine whether these two images are similar or not. In this case, the original visual similarity should be maintained to avoid a random result.
%(3) The Heterogeneity of social data. Different with traditional homogeneous data structure, the data in social media is heterogeneous  and hybrid. For example, a user may publish and favor a lot of images and an image may be shared to a series of interest groups. Therefore, to make our method extensible, we should formulate these multi-modal information in a unified structure.

To address the above problems, we propose a Social-sensed Image Distance Learning (\emph{SIDL}) method to learn image distance from user behavior information in social media platforms. In this method, we use metric learning technique to learn a image distance function of visual features. Different with traditional metric learning work, our distance function aims at making the image distance consistent to their social distance in user behavior. Thus, although the distance function is learned from social images (i.e., the images in social media platforms), it can measure the distance of ordinary Web images because it learns the weight and correlation of visual features. We call this idea ``learn from social image, work beyond social image". Figure \ref{framework} illustrates the framework of our method. In our method, we first estimate the social similarity among the social images. Here the social similarity of image A and B means the probability a user will be interested in B when he has been interested in A. Next, we conduct our metric learning method to reduce the distance of socially similar images and enlarge the distance of socially dissimilar images. Finally, the learned image distance function is used to evaluate the distance of Web images based on their visual features. The image distance can be applied to narrow down user intention in a lot of applications, such as image recommendation and reranking.

The contributions of our proposed approach are summarized as follows:
(1) We propose a novel image distance learning approach, which aims at using user behavior information in social media to bridge the intention gap in Web image distance measuring. To the best of our knowledge, we are the first who use the idea of ``learn from social media, work beyond social media" to solve this problem.

(2) In our approach, an image distance metric function based on visual features is learned to make the image distance consistent to social distance defined from user behavior. In our approach, social distance is well estimated in multiple social factors. In addition, the metric learning method is especially designed to learn social distance from visual features. At the same time, for the images with less social information, their visual distance are maintained.

(3) In this paper, we design two basic application scenario for our proposed \emph{SIDL} method, including image recommendation and image reranking. To evaluate the performance of our approach, comprehensive experiments are conducted based on real social media and image search datasets. The experimental results have shown the improvement of our image distance metric in the above applications.

The rest of the paper is organized as follows: Section 2 gives a brief overview and comparison of related work. In Section 3, we introduce the proposed \emph{SIDL} method. Section 4 presents the applications of our distance learning method. Then we introduce our experiments and report the results in Section 5. Finally, Section 6 summarizes the paper.
